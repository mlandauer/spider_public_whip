#!/usr/bin/env ruby

require 'mechanize'
require 'active_record'
require 'sqlite3'

def get_page_links(url)
  agent = Mechanize.new
  base = URI.parse(url)
  # Ignore links with nil urls
  agent.get(url).links.map{|link| link.href}.compact.map{|link| (base + link).to_s }
end

def db_connect(db)
  ActiveRecord::Base.establish_connection(
    adapter:  'sqlite3', # or 'postgresql' or 'sqlite3'
    database: db
  )
end

class CreateLinks < ActiveRecord::Migration
  def self.up
    create_table :links do |t|
      t.string :url, null: false
      # Whether to follow the links on this page
      t.boolean :spider, null: false
      t.boolean :done, null: false, default: false
      t.timestamps
    end

    add_index :links, [:spider, :done]
  end
end

class Link < ActiveRecord::Base
end

db = "links.sqlite3"

if File.exists?(db) 
  db_connect(db)
else
  db_connect(db)
  # Create the tables we need
  CreateLinks.up
  # And put the first url in it
  Link.create!(url: "http://localhost", spider: true, done: false)
end

link = Link.where(spider: true, done: false).first
puts "#{link.url} (#{Link.where(spider: true, done: false).count} left)"
new_urls = get_page_links(link.url)
ActiveRecord::Base.transaction do
  new_urls.each do |url|
    # So let's spider this one (unless we're already doing it)
    Link.find_or_create_by(url: url, spider: (URI.parse(url).host == "localhost"))
  end
  link.update_attributes(done: true)
end