#!/usr/bin/env ruby

require 'mechanize'
require 'active_record'
require 'sqlite3'

def get_page_links(url)
  agent = Mechanize.new
  base = URI.parse(url)
  # Ignore links with nil urls
  begin
    result = agent.get(url)
  rescue
    puts "WARNING: Error retrieving page #{url}"
    return []
  end
  result.links.map{|link| link.href}.compact.map do |link|
    # Hacky replace spaces with + for badly formatted URLs
    if link.include?(" ")
      puts "WARNING: Fixing URL #{link}"
      link = link.gsub(" ", "+")
    end
    (base + link).to_s
  end
end

def db_connect(db)
  ActiveRecord::Base.establish_connection(
    adapter:  'sqlite3', # or 'postgresql' or 'sqlite3'
    database: db
  )
end

class CreateLinks < ActiveRecord::Migration
  def self.up
    create_table :links do |t|
      t.string :url, null: false
      t.string :source_url
      # Whether to follow the links on this page
      t.boolean :spider, null: false
      t.boolean :done, null: false, default: false
      t.timestamps
    end

    add_index :links, [:spider, :done]
    add_index :links, :url
  end
end

class Link < ActiveRecord::Base
end

db = "links.sqlite3"

if File.exists?(db) 
  db_connect(db)
else
  db_connect(db)
  # Create the tables we need
  CreateLinks.up
  # And put the first url in it
  Link.create!(url: "http://localhost", spider: true, done: false)
end

while !Link.where(spider: true, done: false).empty?
  link = Link.where(spider: true, done: false).first
  puts "#{link.url} (#{Link.where(spider: true, done: false).count} left)"
  new_urls = get_page_links(link.url)
  ActiveRecord::Base.transaction do
    new_urls.each do |url|
      # So let's spider this one (unless we're already doing it)
      if Link.find_by(url: url).nil?
        Link.create(url: url, source_url: link.url, spider: (URI.parse(url).host == "localhost"))
      end
    end
    link.update_attributes(done: true)
  end
end

Link.order(:url).each do |link|
  puts "#{link.url},#{link.source_url}"
end

